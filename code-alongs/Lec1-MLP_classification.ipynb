{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nans? False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "raw_data = load_breast_cancer()\n",
    "X, y = raw_data.data, raw_data.target\n",
    "\n",
    "print(f\"Any nans? {np.isnan(X).any()}\")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train|test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters 2081\n",
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "\n",
    "def MLP():\n",
    "    model = Sequential(name=\"MLP\")\n",
    "    model.add(InputLayer(X.shape[1], name=\"Input_layer\"))\n",
    "    model.add(Dense(32, name=\"Hidden1\", activation=\"relu\")) #Multiples of 2 is often used\n",
    "    model.add(Dense(32, name=\"Hidden2\", activation=\"relu\"))\n",
    "    model.add(Dense(1, name=\"Output\", activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "print(f\"Training parameters {(30+1)*32+(33*32)+33}\")\n",
    "model = MLP()\n",
    "model.summary()\n",
    "\n",
    "#30 features and 32 nodes, (30+1)*32 (1 is the bias term) = 992\n",
    "#32 nodes in first hidden layer and 32 in the second, 33*32 = 1056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 33ms/step - loss: 0.6364 - val_loss: 0.4875\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4020 - val_loss: 0.3324\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2794 - val_loss: 0.2483\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2080 - val_loss: 0.1987\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1633 - val_loss: 0.1691\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1340 - val_loss: 0.1506\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1137 - val_loss: 0.1386\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0995 - val_loss: 0.1307\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0881 - val_loss: 0.1257\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0790 - val_loss: 0.1219\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0724 - val_loss: 0.1201\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0665 - val_loss: 0.1176\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0620 - val_loss: 0.1160\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0582 - val_loss: 0.1138\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0548 - val_loss: 0.1122\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0518 - val_loss: 0.1104\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0494 - val_loss: 0.1086\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0467 - val_loss: 0.1055\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0447 - val_loss: 0.1043\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0430 - val_loss: 0.1045\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0412 - val_loss: 0.1031\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.1039\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0375 - val_loss: 0.1027\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.1025\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0346 - val_loss: 0.1029\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0332 - val_loss: 0.1018\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0311 - val_loss: 0.1042\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0302 - val_loss: 0.1038\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.1029\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0273 - val_loss: 0.1020\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0261 - val_loss: 0.1025\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.1013\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0239 - val_loss: 0.1003\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.1025\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.1037\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0210 - val_loss: 0.1042\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.1036\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.1070\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.1077\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.1079\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.1111\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.1115\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.1142\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.1184\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.1181\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.1262\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.1270\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.1246\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.1261\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.1268\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.1246\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.1238\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.1258\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.1306\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.1332\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.1344\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.1353\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.1382\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.1452\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.1436\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.1422\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.1459\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.1401\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.1436\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.1468\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.1503\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.1477\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.1484\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.1565\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.1613\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.1624\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.1590\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.1590\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.1647\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.1698\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.1669\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.1692\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.1738\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.1753\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.1769\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.1789\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.1791\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.1800\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.1813\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.1830\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.1837\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.1858\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.1867\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.1880\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.1945\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.1996\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.1961\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.2030\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.2033\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.2004\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.2008\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.2002\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.2064\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.2061\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.2067\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.2069\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.2077\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.2101\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.2097\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.9291e-04 - val_loss: 0.2110\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.6851e-04 - val_loss: 0.2103\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.4548e-04 - val_loss: 0.2130\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.2511e-04 - val_loss: 0.2134\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.9897e-04 - val_loss: 0.2160\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.7546e-04 - val_loss: 0.2163\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.5477e-04 - val_loss: 0.2163\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.3092e-04 - val_loss: 0.2179\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.1415e-04 - val_loss: 0.2203\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7.9543e-04 - val_loss: 0.2216\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7466e-04 - val_loss: 0.2220\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.5032e-04 - val_loss: 0.2224\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.3342e-04 - val_loss: 0.2245\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.1772e-04 - val_loss: 0.2254\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.0026e-04 - val_loss: 0.2262\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.8925e-04 - val_loss: 0.2289\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.6466e-04 - val_loss: 0.2273\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.4900e-04 - val_loss: 0.2282\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.3591e-04 - val_loss: 0.2297\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 6.1862e-04 - val_loss: 0.2305\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.3669e-04 - val_loss: 0.2300\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.9600e-04 - val_loss: 0.2338\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.7731e-04 - val_loss: 0.2351\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.6524e-04 - val_loss: 0.2354\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.5302e-04 - val_loss: 0.2352\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.3658e-04 - val_loss: 0.2365\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 5.2576e-04 - val_loss: 0.2376\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.1564e-04 - val_loss: 0.2392\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.0635e-04 - val_loss: 0.2398\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.0531e-04 - val_loss: 0.2441\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.8711e-04 - val_loss: 0.2429\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 4.8085e-04 - val_loss: 0.2416\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.7029e-04 - val_loss: 0.2430\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.5993e-04 - val_loss: 0.2431\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.4599e-04 - val_loss: 0.2450\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.3563e-04 - val_loss: 0.2453\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.2601e-04 - val_loss: 0.2457\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.1468e-04 - val_loss: 0.2449\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.0848e-04 - val_loss: 0.2467\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.9882e-04 - val_loss: 0.2493\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 3.8997e-04 - val_loss: 0.2503\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.8314e-04 - val_loss: 0.2505\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.7652e-04 - val_loss: 0.2513\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.6989e-04 - val_loss: 0.2534\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.6494e-04 - val_loss: 0.2540\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.5729e-04 - val_loss: 0.2539\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3.4794e-04 - val_loss: 0.2565\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.4618e-04 - val_loss: 0.2545\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.3448e-04 - val_loss: 0.2541\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.3211e-04 - val_loss: 0.2551\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.2467e-04 - val_loss: 0.2581\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.1635e-04 - val_loss: 0.2580\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.0964e-04 - val_loss: 0.2594\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.0534e-04 - val_loss: 0.2603\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.9854e-04 - val_loss: 0.2609\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.9853e-04 - val_loss: 0.2606\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.9356e-04 - val_loss: 0.2617\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.8493e-04 - val_loss: 0.2638\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2.8176e-04 - val_loss: 0.2647\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7380e-04 - val_loss: 0.2633\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7098e-04 - val_loss: 0.2642\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2.6442e-04 - val_loss: 0.2653\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2.6438e-04 - val_loss: 0.2668\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.5695e-04 - val_loss: 0.2659\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.5096e-04 - val_loss: 0.2666\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.4652e-04 - val_loss: 0.2676\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2.4563e-04 - val_loss: 0.2672\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.4059e-04 - val_loss: 0.2692\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.3639e-04 - val_loss: 0.2696\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3248e-04 - val_loss: 0.2690\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2620e-04 - val_loss: 0.2713\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2407e-04 - val_loss: 0.2747\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.2159e-04 - val_loss: 0.2741\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1663e-04 - val_loss: 0.2737\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.1415e-04 - val_loss: 0.2739\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.0969e-04 - val_loss: 0.2747\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0734e-04 - val_loss: 0.2761\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0425e-04 - val_loss: 0.2764\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.9879e-04 - val_loss: 0.2770\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.9873e-04 - val_loss: 0.2767\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.9318e-04 - val_loss: 0.2777\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9258e-04 - val_loss: 0.2778\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.8859e-04 - val_loss: 0.2789\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.8426e-04 - val_loss: 0.2811\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.8185e-04 - val_loss: 0.2833\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.7976e-04 - val_loss: 0.2827\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 1.7567e-04 - val_loss: 0.2832\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.7407e-04 - val_loss: 0.2827\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.7026e-04 - val_loss: 0.2851\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.6935e-04 - val_loss: 0.2854\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.6512e-04 - val_loss: 0.2847\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.6329e-04 - val_loss: 0.2854\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6059e-04 - val_loss: 0.2862\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5884e-04 - val_loss: 0.2870\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.5568e-04 - val_loss: 0.2868\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.5380e-04 - val_loss: 0.2879\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.5122e-04 - val_loss: 0.2880\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5146e-04 - val_loss: 0.2888\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4691e-04 - val_loss: 0.2892\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4593e-04 - val_loss: 0.2893\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.4306e-04 - val_loss: 0.2893\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4164e-04 - val_loss: 0.2901\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3966e-04 - val_loss: 0.2907\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.3717e-04 - val_loss: 0.2907\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3526e-04 - val_loss: 0.2915\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3421e-04 - val_loss: 0.2926\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3207e-04 - val_loss: 0.2925\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3036e-04 - val_loss: 0.2929\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.2927e-04 - val_loss: 0.2933\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2672e-04 - val_loss: 0.2941\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2562e-04 - val_loss: 0.2943\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2359e-04 - val_loss: 0.2951\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.2172e-04 - val_loss: 0.2949\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2209e-04 - val_loss: 0.2952\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1972e-04 - val_loss: 0.2963\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.1742e-04 - val_loss: 0.2964\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1614e-04 - val_loss: 0.2969\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.1507e-04 - val_loss: 0.2979\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1305e-04 - val_loss: 0.2979\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1175e-04 - val_loss: 0.2984\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1038e-04 - val_loss: 0.2986\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0923e-04 - val_loss: 0.2996\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0804e-04 - val_loss: 0.2999\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0663e-04 - val_loss: 0.3022\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.0499e-04 - val_loss: 0.3012\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0378e-04 - val_loss: 0.3019\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.0261e-04 - val_loss: 0.3021\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0114e-04 - val_loss: 0.3028\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.9996e-05 - val_loss: 0.3030\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.9078e-05 - val_loss: 0.3035\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.7761e-05 - val_loss: 0.3044\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.7576e-05 - val_loss: 0.3045\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.5593e-05 - val_loss: 0.3045\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.4200e-05 - val_loss: 0.3052\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 9.3491e-05 - val_loss: 0.3059\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.1916e-05 - val_loss: 0.3070\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.1208e-05 - val_loss: 0.3075\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.0227e-05 - val_loss: 0.3070\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.9047e-05 - val_loss: 0.3078\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.7413e-05 - val_loss: 0.3068\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.6482e-05 - val_loss: 0.3081\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.5302e-05 - val_loss: 0.3090\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.4801e-05 - val_loss: 0.3093\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.3204e-05 - val_loss: 0.3101\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.2261e-05 - val_loss: 0.3110\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8.1941e-05 - val_loss: 0.3111\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.0863e-05 - val_loss: 0.3133\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.9589e-05 - val_loss: 0.3133\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.9311e-05 - val_loss: 0.3134\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7872e-05 - val_loss: 0.3145\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.6974e-05 - val_loss: 0.3135\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.5759e-05 - val_loss: 0.3135\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.5428e-05 - val_loss: 0.3132\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 7.4230e-05 - val_loss: 0.3137\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.3481e-05 - val_loss: 0.3148\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7.2983e-05 - val_loss: 0.3155\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.1659e-05 - val_loss: 0.3161\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.0887e-05 - val_loss: 0.3163\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.1346e-05 - val_loss: 0.3157\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.9440e-05 - val_loss: 0.3186\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.9174e-05 - val_loss: 0.3188\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.8031e-05 - val_loss: 0.3198\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.7472e-05 - val_loss: 0.3200\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 6.6379e-05 - val_loss: 0.3193\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 6.5612e-05 - val_loss: 0.3193\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 6.4902e-05 - val_loss: 0.3202\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.4122e-05 - val_loss: 0.3213\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.3388e-05 - val_loss: 0.3211\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.2818e-05 - val_loss: 0.3209\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 6.2088e-05 - val_loss: 0.3223\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 6.1517e-05 - val_loss: 0.3231\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.1016e-05 - val_loss: 0.3231\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 6.0281e-05 - val_loss: 0.3234\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.9640e-05 - val_loss: 0.3245\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.8794e-05 - val_loss: 0.3246\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.8262e-05 - val_loss: 0.3248\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.8505e-05 - val_loss: 0.3248\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 5.6951e-05 - val_loss: 0.3268\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.6613e-05 - val_loss: 0.3269\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.5781e-05 - val_loss: 0.3274\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.5282e-05 - val_loss: 0.3266\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.4986e-05 - val_loss: 0.3264\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.4435e-05 - val_loss: 0.3283\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.3543e-05 - val_loss: 0.3288\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.3037e-05 - val_loss: 0.3281\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.2379e-05 - val_loss: 0.3291\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.1895e-05 - val_loss: 0.3307\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.1583e-05 - val_loss: 0.3306\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.0603e-05 - val_loss: 0.3301\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 5.0239e-05 - val_loss: 0.3304\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.9654e-05 - val_loss: 0.3315\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.9064e-05 - val_loss: 0.3323\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.8417e-05 - val_loss: 0.3331\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.8789e-05 - val_loss: 0.3336\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.7980e-05 - val_loss: 0.3339\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.7115e-05 - val_loss: 0.3339\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.6507e-05 - val_loss: 0.3333\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 4.6284e-05 - val_loss: 0.3344\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.5740e-05 - val_loss: 0.3347\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.5370e-05 - val_loss: 0.3351\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.4848e-05 - val_loss: 0.3360\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.4280e-05 - val_loss: 0.3360\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.3936e-05 - val_loss: 0.3368\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.3631e-05 - val_loss: 0.3371\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.3182e-05 - val_loss: 0.3384\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.2945e-05 - val_loss: 0.3382\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 4.2251e-05 - val_loss: 0.3381\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.1744e-05 - val_loss: 0.3383\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.1616e-05 - val_loss: 0.3389\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.0957e-05 - val_loss: 0.3396\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.0542e-05 - val_loss: 0.3399\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.0165e-05 - val_loss: 0.3404\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.9810e-05 - val_loss: 0.3413\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3.9323e-05 - val_loss: 0.3425\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.8877e-05 - val_loss: 0.3426\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.8447e-05 - val_loss: 0.3429\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.8129e-05 - val_loss: 0.3430\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.7699e-05 - val_loss: 0.3434\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.7436e-05 - val_loss: 0.3442\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.7189e-05 - val_loss: 0.3446\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.7278e-05 - val_loss: 0.3455\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.6417e-05 - val_loss: 0.3453\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.6201e-05 - val_loss: 0.3454\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.6110e-05 - val_loss: 0.3465\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.5350e-05 - val_loss: 0.3463\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.5372e-05 - val_loss: 0.3465\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.4766e-05 - val_loss: 0.3478\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.4437e-05 - val_loss: 0.3484\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.4083e-05 - val_loss: 0.3483\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.3990e-05 - val_loss: 0.3481\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.3410e-05 - val_loss: 0.3484\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.3150e-05 - val_loss: 0.3493\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.3221e-05 - val_loss: 0.3499\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.2575e-05 - val_loss: 0.3501\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.2215e-05 - val_loss: 0.3504\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.1875e-05 - val_loss: 0.3507\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1742e-05 - val_loss: 0.3516\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 3.1757e-05 - val_loss: 0.3513\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.1243e-05 - val_loss: 0.3525\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.0928e-05 - val_loss: 0.3521\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 3.0554e-05 - val_loss: 0.3525\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3.0383e-05 - val_loss: 0.3535\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2.9901e-05 - val_loss: 0.3533\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.9890e-05 - val_loss: 0.3541\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2.9531e-05 - val_loss: 0.3540\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.9219e-05 - val_loss: 0.3552\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 2.8914e-05 - val_loss: 0.3556\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.8627e-05 - val_loss: 0.3555\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2.8463e-05 - val_loss: 0.3558\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.8181e-05 - val_loss: 0.3570\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.7979e-05 - val_loss: 0.3577\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 2.7635e-05 - val_loss: 0.3564\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 2.7483e-05 - val_loss: 0.3581\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7280e-05 - val_loss: 0.3586\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.6813e-05 - val_loss: 0.3599\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.6669e-05 - val_loss: 0.3598\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.6190e-05 - val_loss: 0.3610\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.6197e-05 - val_loss: 0.3608\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5964e-05 - val_loss: 0.3607\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.5558e-05 - val_loss: 0.3603\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.5200e-05 - val_loss: 0.3619\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2.5146e-05 - val_loss: 0.3621\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.5292e-05 - val_loss: 0.3639\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.4829e-05 - val_loss: 0.3632\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.4370e-05 - val_loss: 0.3632\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4111e-05 - val_loss: 0.3622\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3927e-05 - val_loss: 0.3628\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.3632e-05 - val_loss: 0.3641\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3383e-05 - val_loss: 0.3644\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.3169e-05 - val_loss: 0.3649\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.2953e-05 - val_loss: 0.3659\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 2.2818e-05 - val_loss: 0.3663\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2513e-05 - val_loss: 0.3667\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.2379e-05 - val_loss: 0.3667\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.2238e-05 - val_loss: 0.3671\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.2370e-05 - val_loss: 0.3699\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.2127e-05 - val_loss: 0.3694\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 2.1692e-05 - val_loss: 0.3701\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.1637e-05 - val_loss: 0.3696\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.1263e-05 - val_loss: 0.3692\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1012e-05 - val_loss: 0.3696\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.0901e-05 - val_loss: 0.3697\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.0683e-05 - val_loss: 0.3716\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.0489e-05 - val_loss: 0.3710\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.0269e-05 - val_loss: 0.3717\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.0052e-05 - val_loss: 0.3721\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.9997e-05 - val_loss: 0.3726\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.0071e-05 - val_loss: 0.3735\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.9835e-05 - val_loss: 0.3731\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.9479e-05 - val_loss: 0.3733\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.9227e-05 - val_loss: 0.3741\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9033e-05 - val_loss: 0.3741\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.8976e-05 - val_loss: 0.3745\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.8542e-05 - val_loss: 0.3760\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8644e-05 - val_loss: 0.3758\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.8419e-05 - val_loss: 0.3757\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8196e-05 - val_loss: 0.3764\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.8086e-05 - val_loss: 0.3769\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.7943e-05 - val_loss: 0.3778\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7723e-05 - val_loss: 0.3773\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 1.7621e-05 - val_loss: 0.3777\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.7511e-05 - val_loss: 0.3799\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.7382e-05 - val_loss: 0.3800\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7124e-05 - val_loss: 0.3792\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7051e-05 - val_loss: 0.3793\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6938e-05 - val_loss: 0.3806\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.6746e-05 - val_loss: 0.3805\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.6573e-05 - val_loss: 0.3810\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6454e-05 - val_loss: 0.3814\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.6300e-05 - val_loss: 0.3823\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1.6152e-05 - val_loss: 0.3819\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.6080e-05 - val_loss: 0.3828\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.5994e-05 - val_loss: 0.3825\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5775e-05 - val_loss: 0.3832\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5702e-05 - val_loss: 0.3835\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.5504e-05 - val_loss: 0.3837\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5384e-05 - val_loss: 0.3838\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.5216e-05 - val_loss: 0.3851\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 1.5269e-05 - val_loss: 0.3865\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.5174e-05 - val_loss: 0.3872\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4949e-05 - val_loss: 0.3871\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4759e-05 - val_loss: 0.3870\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4628e-05 - val_loss: 0.3881\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.4495e-05 - val_loss: 0.3875\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4448e-05 - val_loss: 0.3882\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4277e-05 - val_loss: 0.3882\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4135e-05 - val_loss: 0.3883\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4065e-05 - val_loss: 0.3879\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3912e-05 - val_loss: 0.3887\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3794e-05 - val_loss: 0.3890\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3734e-05 - val_loss: 0.3895\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.3618e-05 - val_loss: 0.3902\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3520e-05 - val_loss: 0.3904\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3363e-05 - val_loss: 0.3906\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3312e-05 - val_loss: 0.3914\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.3183e-05 - val_loss: 0.3914\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3048e-05 - val_loss: 0.3918\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.3032e-05 - val_loss: 0.3936\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2950e-05 - val_loss: 0.3926\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.2750e-05 - val_loss: 0.3926\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.2656e-05 - val_loss: 0.3937\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1.2501e-05 - val_loss: 0.3943\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.2444e-05 - val_loss: 0.3943\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2317e-05 - val_loss: 0.3946\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.2260e-05 - val_loss: 0.3949\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.2213e-05 - val_loss: 0.3957\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.2089e-05 - val_loss: 0.3958\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2002e-05 - val_loss: 0.3957\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.1866e-05 - val_loss: 0.3961\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.1717e-05 - val_loss: 0.3969\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 1.1604e-05 - val_loss: 0.3975\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1503e-05 - val_loss: 0.3981\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1456e-05 - val_loss: 0.3997\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1358e-05 - val_loss: 0.3996\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.1249e-05 - val_loss: 0.3993\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1172e-05 - val_loss: 0.3993\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1041e-05 - val_loss: 0.4000\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1008e-05 - val_loss: 0.3998\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0883e-05 - val_loss: 0.4012\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.0787e-05 - val_loss: 0.4014\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0703e-05 - val_loss: 0.4017\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1.0640e-05 - val_loss: 0.4019\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0559e-05 - val_loss: 0.4018\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0428e-05 - val_loss: 0.4025\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0374e-05 - val_loss: 0.4029\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 1.0316e-05 - val_loss: 0.4043\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0217e-05 - val_loss: 0.4041\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1.0298e-05 - val_loss: 0.4029\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0078e-05 - val_loss: 0.4035\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9.9775e-06 - val_loss: 0.4045\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9.8833e-06 - val_loss: 0.4052\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.8146e-06 - val_loss: 0.4049\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.7367e-06 - val_loss: 0.4053\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.6614e-06 - val_loss: 0.4056\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.5871e-06 - val_loss: 0.4062\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.5359e-06 - val_loss: 0.4058\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.4605e-06 - val_loss: 0.4066\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.3911e-06 - val_loss: 0.4079\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.3039e-06 - val_loss: 0.4078\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.2219e-06 - val_loss: 0.4080\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.1598e-06 - val_loss: 0.4087\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9.0493e-06 - val_loss: 0.4084\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.0250e-06 - val_loss: 0.4089\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8.9175e-06 - val_loss: 0.4096\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.8713e-06 - val_loss: 0.4099\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.7844e-06 - val_loss: 0.4105\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.7067e-06 - val_loss: 0.4106\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.6499e-06 - val_loss: 0.4107\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.6241e-06 - val_loss: 0.4114\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5510e-06 - val_loss: 0.4120\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.4911e-06 - val_loss: 0.4117\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 8.3855e-06 - val_loss: 0.4119\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.3222e-06 - val_loss: 0.4128\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.2838e-06 - val_loss: 0.4134\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8.2686e-06 - val_loss: 0.4128\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.1450e-06 - val_loss: 0.4136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152d59cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs=500, validation_split=.2, verbose=1) #Use validation_split so then it will automatically split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.636419</td>\n",
       "      <td>0.487494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.401961</td>\n",
       "      <td>0.332411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279374</td>\n",
       "      <td>0.248343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.207954</td>\n",
       "      <td>0.198665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163328</td>\n",
       "      <td>0.169143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.636419  0.487494\n",
       "1  0.401961  0.332411\n",
       "2  0.279374  0.248343\n",
       "3  0.207954  0.198665\n",
       "4  0.163328  0.169143"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_loss = pd.DataFrame(model.history.history) #Do not run this two times\n",
    "df_loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_loss.plot()\n",
    "#Clear overfitting, as validation loss increases after a certain amount of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 25ms/step - loss: 0.7200 - val_loss: 0.6192\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5462 - val_loss: 0.4769\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4076 - val_loss: 0.3593\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2954 - val_loss: 0.2709\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2166 - val_loss: 0.2130\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1651 - val_loss: 0.1807\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1355 - val_loss: 0.1622\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1152 - val_loss: 0.1516\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1009 - val_loss: 0.1425\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0893 - val_loss: 0.1364\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0808 - val_loss: 0.1302\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0736 - val_loss: 0.1263\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0677 - val_loss: 0.1231\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0625 - val_loss: 0.1205\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0585 - val_loss: 0.1178\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0547 - val_loss: 0.1159\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0518 - val_loss: 0.1126\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0485 - val_loss: 0.1107\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0459 - val_loss: 0.1093\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0435 - val_loss: 0.1081\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0414 - val_loss: 0.1073\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0392 - val_loss: 0.1067\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0377 - val_loss: 0.1053\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0354 - val_loss: 0.1056\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0338 - val_loss: 0.1050\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0323 - val_loss: 0.1037\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0306 - val_loss: 0.1035\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.1033\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.1042\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0264 - val_loss: 0.1037\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0248 - val_loss: 0.1051\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0237 - val_loss: 0.1045\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0224 - val_loss: 0.1058\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0212 - val_loss: 0.1066\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.1063\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.1075\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0180 - val_loss: 0.1084\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.1101\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0163 - val_loss: 0.1106\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.1128\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0146 - val_loss: 0.1128\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.1125\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.1139\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.1133\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.1133\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.1130\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.1125\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.1125\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.1146\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.1153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x154625a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs=50, validation_split=.2, verbose=1) #Use validation_split so then it will automatically split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot() #Do not run this two times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1547e3b20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.fit(scaled_X_train, y_train, epochs=50, verbose=0) #Use validation_split so then it will automatically split the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        43\n",
      "           1       0.99      0.97      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "y_pred = (y_pred > .5)*1\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8622f42dd2024023add1dc3af682913d650e689fa358b3965b6044288c201ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('Deep-Learning-Anna-MariaSjolund-0DMhVJHL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
